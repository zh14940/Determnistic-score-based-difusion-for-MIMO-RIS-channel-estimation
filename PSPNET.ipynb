{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6b60ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhizhou He\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  292272\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlockEnc(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels,out_channels, stride=1):\n",
    "        super(BasicBlockEnc, self).__init__()\n",
    "        in_channels =2 \n",
    "        out_channels = in_channels*stride\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if stride == 1:\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        #print(\"conv2 output size:\", out.size())\n",
    "        if hasattr(self, 'shortcut'):\n",
    "            shortcut_out = self.shortcut(x)\n",
    "            #print(\"shortcut output size:\", shortcut_out.size())\n",
    "        else:\n",
    "            shortcut_out = x\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18cus(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], nc=2):\n",
    "        super().__init__()\n",
    "        self.in_channels = 2\n",
    "        self.conv1 = nn.Conv2d(nc, 2, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(2)\n",
    "        self.layer1 = self._make_layer(BasicBlockEnc, 8, 2, stride=1) ######## 2 is the number of basic blocks\n",
    "        self.layer2 = self._make_layer(BasicBlockEnc, 16, 2, stride=1)\n",
    "        self.layer3 = self._make_layer(BasicBlockEnc, 32, 2, stride=1)\n",
    "        self.layer4 = self._make_layer(BasicBlockEnc, 64, 2, stride=1)\n",
    "        self.linear = nn.Linear(64,2048)\n",
    "\n",
    "    def _make_layer(self, BasicBlockEnc,out_channels, num_Blocks, stride):\n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers += [BasicBlockEnc(self.in_channels, stride)]\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PPM(nn.ModuleList):\n",
    "    def __init__(self, pool_sizes, in_channels, out_channels):\n",
    "        super(PPM, self).__init__()\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        for pool_size in pool_sizes:\n",
    "            self.append(\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveMaxPool2d(pool_size),\n",
    "                    nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1),\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out_puts = []\n",
    "        for ppm in self:\n",
    "            ppm_out = nn.functional.interpolate(ppm(x), size=x.size()[-2:], mode='bilinear', align_corners=True)\n",
    "            out_puts.append(ppm_out)\n",
    "        return out_puts\n",
    " \n",
    "    \n",
    "class PSPHEAD(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,pool_sizes = [1, 2, 3, 6],num_classes=3):\n",
    "        super(PSPHEAD, self).__init__()\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.psp_modules = PPM(self.pool_sizes, self.in_channels, self.out_channels)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels + len(self.pool_sizes)*self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.psp_modules(x)\n",
    "        out.append(x)\n",
    "        out = torch.cat(out, 1)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    " \n",
    "# 构建一个FCN分割头，用于计算辅助损失\n",
    "class Aux_Head(nn.Module):\n",
    "    def __init__(self, in_channels=1024, num_classes=3):\n",
    "        super(Aux_Head, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    " \n",
    "        self.decode_head = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.in_channels//2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.in_channels//2),\n",
    "            nn.ReLU(),            \n",
    "            \n",
    "            nn.Conv2d(self.in_channels//2, self.in_channels//4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.in_channels//4),\n",
    "            nn.ReLU(),            \n",
    "            \n",
    "            nn.Conv2d(self.in_channels//4, self.num_classes, kernel_size=3, padding=1),\n",
    " \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        return self.decode_head(x)\n",
    " \n",
    "class Pspnet(nn.Module):\n",
    "    def __init__(self, num_classes, aux_loss = True):\n",
    "        super(Pspnet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.backbone = IntermediateLayerGetter(\n",
    "            ResNet18cus(),\n",
    "            return_layers={'layer3':\"aux\" ,'linear': 'stage4'}\n",
    "        )\n",
    "        self.aux_loss = aux_loss\n",
    "        self.decoder = PSPHEAD(in_channels=64, out_channels=32, pool_sizes = [1, 2, 3, 6], num_classes=self.num_classes)\n",
    "        self.cls_seg = nn.Sequential(\n",
    "            nn.Conv2d(32, self.num_classes, kernel_size=3, padding=1),\n",
    "        )\n",
    "        if self.aux_loss:\n",
    "            self.aux_head = Aux_Head(in_channels=128, num_classes=self.num_classes)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        feats = self.backbone(x)\n",
    "        last_loss = feats[\"stage4\"].view(-1,64,64,64)\n",
    "        x = self.decoder(last_loss)\n",
    "        x = self.cls_seg(x)\n",
    "        segmentation = x ##################derive segmentation\n",
    "        x = nn.functional.interpolate(x, size=(h, w),mode='bilinear', align_corners=True)\n",
    " \n",
    "        # 如果需要添加辅助损失\n",
    "        if self.aux_loss:\n",
    "            aux_output = self.aux_head(feats['aux'].view(-1,128,8,8))\n",
    "            aux_output = nn.functional.interpolate(aux_output, size=(h, w),mode='bilinear', align_corners=True)\n",
    " \n",
    "            return {\"output\":x, \"aux_output\":aux_output}\n",
    "        return {\"output\":x}\n",
    " \n",
    " \n",
    "# if __name__ == \"__main__\":\n",
    "#     model = Pspnet(num_classes=4, aux_loss=True)\n",
    "#     model = model.cuda()\n",
    "#     a = torch.ones([10, 2, 64, 64])\n",
    "#     a = a.cuda()\n",
    " \n",
    "#     for name, out in model(a).items():\n",
    "#         print(name,\": \", out.shape)\n",
    "model = Pspnet(num_classes=4, aux_loss=True)\n",
    "model = model.cuda()\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb286c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11492919921875\n"
     ]
    }
   ],
   "source": [
    "model_size_bytes = sum(p.numel() for p in model.parameters()) * 4  # numel()返回参数的总元素数，乘以4字节得到总字节数\n",
    "model_size_mb = model_size_bytes / (1024 ** 2)  # 将字节转换为兆字节\n",
    "print(model_size_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bdc8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in Aux_Head: 5907459\n"
     ]
    }
   ],
   "source": [
    "in_channels = 1024\n",
    "num_classes = 3\n",
    "\n",
    "# 卷积层参数\n",
    "conv1_params = (in_channels * (in_channels//2) * 3**2) + (in_channels//2)\n",
    "conv2_params = ((in_channels//2) * (in_channels//4) * 3**2) + (in_channels//4)\n",
    "conv3_params = ((in_channels//4) * num_classes * 3**2) + num_classes\n",
    "\n",
    "# 批量归一化层参数\n",
    "bn1_params = (in_channels//2) * 2\n",
    "bn2_params = (in_channels//4) * 2\n",
    "\n",
    "# 总参数数量\n",
    "total_params = conv1_params + bn1_params + conv2_params + bn2_params + conv3_params\n",
    "\n",
    "print(\"Total parameters in Aux_Head:\", total_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
